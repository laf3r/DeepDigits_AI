---
license: gpl-2.0
---
# DeepDigits_AI
## Нейронная сеть для классификации цифр с точностью 99.4%
![image](https://user-images.githubusercontent.com/101829424/235917558-4b4642e8-8808-4938-84bf-27de5592b442.png)

## Введение
Цель данной работы - создание нейронной сети для распознавания цифр с предельно высокой точностью. Была выбрана задача многоклассовой классификации, на выходном слое содержится десять нейронов, представляющие цифры от "0" до "9".


## Архитектура сети
Нейронная модель основана на архитектуре свёрточной сети (Convolutional Neural Network, CNN). В качестве тренировочного набора данных использовался набор рукописных цифр 
[MNIST](https://www.tensorflow.org/datasets/catalog/mnist?hl=ru). Модель предназначена для работы на тензорных процессорах (TPU). За счёт этого, и отсутствия переобучения достигается предельно высокая точность на валидационных данных. 
![model (1)](https://user-images.githubusercontent.com/101829424/235922343-c069317a-0b61-44dd-b518-83c24ebe336b.png)

Сверточный слой с 32 фильтрами размера (3, 3) и функцией активации ReLU, который принимает на вход изображения размера (28, 28, 1).
- Слой BatchNormalization для нормализации выходов предыдущего слоя.
- Сверточный слой с 64 фильтрами размера (3, 3) и функцией активации ReLU.
- Слой BatchNormalization для нормализации выходов предыдущего слоя.
- Слой MaxPooling2D с размером пула (2, 2).
- Слой Dropout с коэффициентом 0.25 для регуляризации.
- Сверточный слой с 128 фильтрами размера (3, 3) и функцией активации ReLU.
- Слой BatchNormalization для нормализации выходов предыдущего слоя.
- Сверточный слой с 256 фильтрами размера (3, 3), функцией активации ReLU и регуляризацией L2 со значением 0.001.
- Слой BatchNormalization для нормализации выходов предыдущего слоя.
- Слой MaxPooling2D с размером пула (2, 2).
- Слой Dropout с коэффициентом 0.25 для регуляризации.
- Слой Flatten для преобразования выходов сверточных слоев в одномерный вектор.
- Полносвязный слой с 512 нейронами и функцией активации ReLU, а также регуляризацией L2 со значением 0.001.
- Слой BatchNormalization для нормализации выходов предыдущего слоя.
- Слой Dropout с коэффициентом 0.5 для регуляризации.
- Полносвязный слой с 256 нейронами и функцией активации ReLU, а также регуляризацией L2 со значением 0.001.
- Слой BatchNormalization для нормализации выходов предыдущего слоя.
- Слой Dropout с коэффициентом 0.5 для регуляризации.
- Полносвязный слой с 10 нейронами и функцией активации softmax для классификации изображений на 10 классов, т. е. для цифр от '0' до '9'.

Общее количество параметров 2,624,394.

## Функция потерь и оптимизатор
<img width="639" alt="Screenshot_6" src="https://user-images.githubusercontent.com/101829424/235925205-8a17223b-e1e4-4b03-a45f-eb3a35b77eeb.png">
Для задачи многоклассовой классификации была выбрана функция потерь SparseCategoricalCrossentropy, в качестве оптимизатора используется Adam. Для оценки качества используется метрика sparse_categorical_accuracy.

## Результат
<img width="781" alt="Screenshot_5" src="https://user-images.githubusercontent.com/101829424/235924949-10dc4a1c-1ad1-42d8-bcc5-98d4ed2d2dc0.png">
Модель имеет защиту от переобучения и имееет совершенную точность для многоклассовой классификации цифр.
Модель доступна для скачивания на huggingface: https://huggingface.co/Innokentiy/DeepDigits_AI

>Программа предоставляется в виде открытого исходного кода.
